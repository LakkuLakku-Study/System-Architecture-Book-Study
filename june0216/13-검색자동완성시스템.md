- 자동 완성 기능
    - 입력 중인 글자에 맞는 검색어가 자동으로 완성되어 표시

# 1단계 문제 이해 및 설계 범위 확정

### 질의응답

- 자동완성될 검색어의 첫부분을 보여주어야 하는지? 검색어의 중간 부분도 될 수 있는지?
    - 첫 부분으로 한정
- 자동완성 검색어 표시 개수
    - 5개
- 검색어를 고르는 기준
    - 질의 빈도에 따라 정해지는 인기 순위
- 지원 언어
    - 다국어
- 대문자나 특수 문자 처리
    - 모든 질의는 영어 소문자로 이루어진다고 가정
- 사용자 수
    - DAU 기준으로 천만

### 요구사항

1. **빠른 응답 속도** 
    1. 사용자가 검색어를 입력함에 따라 자동 완성 검색어가 충분히 빨리 표시되어야 한다. 
    2. 시스템 응답속도는 **100밀리초 이내**여야 한다. → 그 이상이면 시스템 이용이 불편해진다. 
2. **연관성**
    1. 자동완성 검색어는 입력한 단어와 연관되어야 한다.
3. **정렬**
    1. 계산 결과는 인기도 등의 **순위 모델에 의해 정렬**되어야 한다.
4. **규모 확장성** 
    1. 많은 트래픽을 감당할 수 있도록 **확장 가능**해야 한다.
5. **고가용성** 
    1. 시스템 일부에 장애 발생 or 느려지거나 or 예상치 못한 네트워크 문제가 생겨도 계속 사용 가능해야 한다.

### 개략적 규모 추정

- 일간 능동 사용자(DAU)는 천만 명으로 가정
- 평균적으로 한 사용자는 **매일 10건의 검색을 수행**한다고 가정
- 질의할 때마다 **평균적으로 20바이트의 데이터를 입력**한다고 가정
    - ASCII를 사용한다고 가정하면, 1 문자 = 1 바이트
    - 질의문은 평균적으로 4단어, 각 단어는 평균적으로 5글자로 구성된다고 가정하면 → **질의당 평균 20바이트** 이다.
        - ex) hello world again test
            - 4단어, 각 단어가 5글자
- 검색창에 글자를 입력할 때마다 클라이언트는 검색어 자동완성 백엔드에 요청을 보낸다.
    - 평균적으로 1회 검색당 20건의 요청이 백엔드로 전달된다.
    - ex) dinner이라고 입력하면 6개의 요청이 백엔드에 전송된다.
        - search?q=d
        - search?q=di
        - search?q=din
        - search?q=dinn
        - search?q=dinne
        - search?q=dinner
- 대략 초당 24,000건의 질의(QPS)가 발생할 것이다.
    - 사용자 수: 10,000,000명 (천만 사용자)
    - 사용자당 질의 수: 하루에 10질의
    - 평균 질의 길이: 20자 (20바이트)
    - 하루의 시간: 24시간 = 24 * 3600초 = 86,400초
    - ⇒ 10,000,000명 x 10질의 x 20자 / 24시간 / 3600초 = 24,000
- 최대 QPS = QPS x 2 = 대략 48,000
    - 시스템이 피크 트래픽 상황에서도 견딜 수 있도록 설계해야 하기 때문 → 일반적으로 평균 QPS에 안전한 계수를 곱하여 최대 QPS를 계산한다. 여기서는 2가 안전한 계수로 설정

- 질의 가운데 20%는 신규 검색어라고 가정할 것이다.
    - 천만 사용자 x 10질의 / 일 x 20자 x 20% = 대략 0.4GB
    - **매일 0.4GB의 신규 데이터가 시스템에 추가**된다.

# 2단계 : 계략적인 설계 안 제시 및 동의 구하기

개략적으로 보면 시스템은 두 부분으로 나뉜다.

- **데이터 수집 서비스**
    - 사용자가 입력한 질의를 실시간으로 수집하는 시스템
    - → 데이터가 많은 애플리케이션에 실시간 시스템은 바람직하지 않음 😢
- **질의 서비스**
    - 주어진 질의에 다섯 개의 인기 검색어를 정렬해서 내놓는 서비스

### 1) 데이터 수집 서비스

- 질의문과 사용빈도를 저장하는 **빈도 테이블**이 있다고 가정한다.
- 처음에는 테이블이 비어있다.
    - 그리고 사용자가 twitch, twitter, twitter, twillo를 순서대로 검색하면 아래와 같이 바뀌어 나간다.

https://github.com/sangminlee98/system-design-interview/assets/83197138/6f0ff5ee-1303-4630-be33-842f3e71cefd

### 2) 질의 서비스

- 아래와 같은 빈도 테이블이 있는 상태이다.
    - query : 질의문을 저장하는 필드
    - frequency : 질의문이 사용된 빈도를 저장하는 필드
- 사용자가 “tw”를 검색창에 입력하면 아래의 빈도 테이블에서 빈도수가 높은 5개를 정렬하여 자동완성 검색어가 표시되어야 한다.

https://github.com/sangminlee98/system-design-interview/assets/83197138/3497fa13-46e8-4d2b-8d47-27ffe48d2608

https://github.com/sangminlee98/system-design-interview/assets/83197138/2c7114e5-68a7-41bf-88a5-c52c953dd9f8

- 가장 많이 사용된 5개 검색어는 아래의 SQL 질의문을 사용해 계산할 수 있다.
    
    ```sql
    SELECT * FROM frequency_table
    WHERE query Like `prefix%`
    ORDER BY frequency DESC
    LIMIT 5;
    ```
    

→ 데이터 양이 적을 때는 나쁘지 않은 설계

→ 데이터가 많아진다면 **데이터베이스 병목**이 될 수 있음.

# 3단계 : 상세 설계

- 데이터 수집 서비스와 질의 서비스의 두 부분으로 구성된 개략적 설계안은 최적의 결과물이라고는 말하기 어렵다.
    - → 최적화 방안을 논의할 것이다. + 컴포넌트에 대한 상세한 설계
- 설명할 내용
    - 트라이(trie) 자료구조
    - 데이터 수집 서비스
    - 질의 서비스
    - 규모 확장이 가능한 저장소
    - 트라이 연산

## 트라이 자료구조

- 개략적 설계안에서는 관계형 데이터베이스를 저장소로 사용했음. → 5개의 질의문을 골라내는 것은 효율적이지 않다.
    - **→ 트라이를 사용하여 해결할 수 있다.** 🌟
- 트라이 (trie) 란?
    - 문자열들을 간략하게 저장할 수 있는 자료구조
    - retrieval → 문자열을 **꺼내는 연산에 초점을 맞추어** 설계된 자료구조이다.
    - 방법
        - 트리 형태의 자료구조
        - 루트 노드는 빈 문자열을 나타냄
        - 각 노드는 글자 하나를 저장하며 26개의 **자식 노드**를 가질 수 있음
            - 자식 노드 == 부모 노드 글자 다음에 등장할 수 있는 모든 글자
        - 각 트리 노드는 하나의 단어, 또는 접두어 문자열을 나타냄
    - 예시 ) 아래는 `tree`, `try`, `true`, `toy`, `wish`, `win` 가 보관된 트라이이다.
        
        https://github.com/sangminlee98/system-design-interview/assets/83197138/9fc336d7-36dd-4612-afe1-7d9213f3aee0
        
        - + 빈도에 따라 정렬된 결과를 내놓기 위해 트라이에 빈도 정보도 저장해야 한다.
            
            ![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/e2c6ccd4-4439-43db-96e9-e654aaf4aa71/99742d08-5f25-434c-943f-77e6197f4210/Untitled.png)
            
    - 이 빈도 정보를 트라이 노드에 저장하게 된다면 아래의 상태가 될 것이다.
        
        ![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/e2c6ccd4-4439-43db-96e9-e654aaf4aa71/f247fb10-f612-449a-97c0-60605b39eafc/Untitled.png)
        

- 해당 트라이로 검색어 자동완성을 어떻게 구현할 수 있을까?
    - p: 접두어(prefix)의 길이
    - n: 트라이 안에 있는 노드 개수
    - c: 주어진 노드의 자식 노드 개수
- ✔️가장 많이 사용된 질의어 k개를 찾는 방법
    - 해당 접두어를 표현하는 **노드를 찾는다.**
        - → 시간복잡도 O(p)
    - 해당 노드부터 시작하는 **하위 트리를 탐색**하여 모든 유효 노드를 찾는다.
        - → 시간복잡도 O(c)
    - 유효 노드들을 정렬하여 가장 인기 있는 검색어 k개를 찾는다.
        - → 시간복잡도 O(clogc)
    - 전체 알고리즘 복잡도 = **O(p) + O(c) + O(clogc)**
- 예제) k=2이고, 사용자가 검색창에 “be”를 입력한 경우
    
    https://github.com/sangminlee98/system-design-interview/assets/83197138/5d5b4f50-6b2d-4842-bab0-ea5f8466e29f
    
1. 접두어 노드 `be`를 찾는다.
2. 해당 노드부터 시작하는 하위 트리를 탐색하여 모든 유효 노드를 찾는다.[beer: 10], [best: 35], [bet: 29]가 유효 노드
3. 유효 노드를 정렬하여 2개만 골라낸다. 
    1. 결과 →  [best: 35], [bet: 29]

- 시간 복잡도 위의 각 단계에 소요된 시간의 합
    - O(p) + O(c) + O(clogc)
- 🦹‍♂️ 최악의 경우 **전체 트라이를 다 검색해야 하는 일**이 생길 수 있음ㅜ
    - 해결 방안 가지
        - 1) 접두어의 최대 길이를 제한
        - 2) 각 노드에 인기 검색어를 캐시

### 접두어 최대 길이 제한

- 사용자가 검색창에 긴 검색어를 입력하는 일은 거의 없음.
    
    → 따라서 p값은 작은 정숫값이라고 가정해도 안전하다.
    
    → 시간복잡도는 O(p)에서 O(작은 상숫값) = O(1)로 바뀔 것이다.
    

### 노드에 인기 검색어 캐시

- 각 노드에 k개의 인기 검색어를 저장해 두면 전체 트라이를 검색하는 일을 방지할 수 있음.
    - 5~10개 정도의 자동완성 제안을 표시하면 충분 → k는 작은 값
        - ⚡각 노드에 인기 질의어를 캐시하면 top5 검색어를 질의하는 시간 복잡도를 엄청나게 낮출 수 있다.
        - 하지만 각 노드에 질의어를 저장할 공간이 많이 필요하게 된다는 단점도 있다.
            - 하지만 빠른 응답속도가 아주 중요할 때는 이 정도 저장공간은 희생할만함

- 개선된 트라이 구조 → 접두어 최대 길이 제한 방법 + 노드에 인기 검색어 캐시 방법 반영
    - 각 노드에 가장 인기 있는 검색어 다섯가지를 저장
    - ex) b에는  5개 캐시[best, bet, bee, be, buy]
- 개선점
    - 1) 접두어 노드를 찾는 시간 접두어 최대 길이 제한했기 때문에 O(p) → O(1) 로 개선
    - 2) 최고 인기 검색어 5개를 캐시했기 때문에 O(c)→ O(1) 로 개선

https://github.com/sangminlee98/system-design-interview/assets/83197138/a4349c00-1359-418f-ab19-16cb12b8db0e

- 각 단계의 시간 복잡도가 O(1)로 바뀐 덕분에 최고 인기 검색어 k개를 찾는 전체 알고리즘의 복잡도는 **O(1)**로 바뀌게 된다.

## 데이터 수집 서비스

- 지금까지의 설계안은 사용자가 검색창에 뭔가 타이핑을 할 때마다 **실시간으로 데이터를 수정**했다.
    - 1) 하지만 매일 수천만 건의 질의가 입력될 텐데 **그때마다 트라이를 갱신하면 질의 서비스는 심각하게 느려질 것**이다.
    - 2) 일단 트라이가 만들어지고 나면 **인기 검색어는 그다지 자주 바뀌지 않을 것이므로 자주 갱신할 필요 없음**

- 규모 확장이 쉬운 데이터 수집 서비스를 만들려면 데이터가 어디서 오고 어떻게 이용되는지 살펴야 한다.
    - 트위터같은 실시간 애플리케이션이라면 항상 신선하게 유지할 필요가 있지만
    - 구글 검색 같은 애플리케이션은 그렇게 자주 바꿔줄 이유는 없다.
    
    → 용례에 따라 서비스를 설계하면 된다.
    
    만약 용례가 바뀌어도 서비스의 토대는 변하지 않는다. 트라이를 만드는 데 쓰이는 데이터는 보통 데이터 분석 서비스나 로그 시스템과 같은 곳에서 올 것이기 때문
    

- 아래는 수정된 데이터 분석 서비스의 설계안.

https://github.com/sangminlee98/system-design-interview/assets/83197138/e613c44e-ff25-4285-b1c2-c19f3d77288d

### 1) 데이터 분석 서비스 로그

- 검색창에 입력된 질의에 관한 원본 데이터가 보관된다.
- 데이터가 추가될 뿐 수정은 이루워지지 않으며 로그 데이터에는 인덱스를 걸지 않는다.

https://github.com/sangminlee98/system-design-interview/assets/83197138/32ca3def-5ac3-4d76-be67-934809a2c1e0

### 2) 로그 취합 서버

- 데이터 분석 서비스로부터 나오는 로그는 보통 그 양이 엄청나고 데이터 형식도 제각각인 경우가 많다.
    - → 이 데이터를 잘 취합하여 우리 시스템이 쉽게 소비할 수 있도록 해야한다.
- 데이터 취합 방식은 우리 서비스 “용례”에 따라 달라질 수 있다.
    - ex) 트위터와 같은 실시간 애플리케이션 (결과를 빨리 보여주는 것이 중요)→ 데이터 취합 주기를 짧게 가져가는 것이 좋음 → 면접에서 데이터 취합의 실시간성이 얼마나 중요한지 물어보자
    - 대부분의 경우 → **일주일에 한 번 정도로 로그를 취합**
    

### 3) 취합된 데이터

- 매주 데이터를 취합하는 경우
    - → time 필드는 해당 주가 시작한 날짜를 나타냄
    - → frequency 필드는 해당 질의가 해당 주에 사용된 횟수의 합

https://github.com/sangminlee98/system-design-interview/assets/83197138/b9a7315e-e9e6-462c-84d7-586da9982e43

### 4) 작업 서버

- 작업 서버(worker)는 주기적으로 비동기적 작업(job)을 실행하는 서버 집합.
- **트라이 자료구조를 만들고 트라이 데이터베이스에 저장**하는 역할을 담당

### 5) 트라이 캐시

- 분산 캐시 시스템 → 트라이 데이터를 메모리에 유지하여 읽기 연산 성능을 높임
- 매주 트라이 데이터베이스의 스냅샷을 떠서 갱신한다.

### 6) 트라이 데이터베이스

- 트라이 데이터베이스는 지속성 저장소.
- 트라이 데이터베이스로 사용할 수 있는 2가지 선택지
    1. 문서 저장소
        - 새 트라이를 매주 만들 것이므로 주기적으로 트라이를 직렬화하여 데이터베이스에 저장할 수 있음
        - 몽고디비 같은 문서 저장소를 활용하면 편리하게 저장할 수 있다.
    2. 키-값 저장소
        - 해시 테이블 형태로 변환 가능 로직
            - 1) 트라이에 보관된 모든 접두어를 해시 테이블 키로 변환
            - 2) 각 트라이 노드에 보관된 모든 데이터를 해시 테이블 값을 변환
        
        https://github.com/sangminlee98/system-design-interview/assets/83197138/5e550841-db93-4e81-abfe-e77a72a94df7
        

## 질의 서비스

- 최고 인기 검색어 5개를 골라내는 설계안에서 비효율성을 개선한 것이다.

https://github.com/sangminlee98/system-design-interview/assets/83197138/fe954ee6-7139-4f0e-92ad-6337e4afb121

1. 검색 질의가 로드밸런서로 전송
2. 로드밸런서는 해당 질의를 API 서버로 전달
3. API 서버는 트라이 캐시에서 데이터를 가져와 해당 요청에 대한 자동완성 검색어 제안 응답을 구성
4. 데이터가 트라이 캐시에 없는 경우 트라이 데이터베이스에서 가져와 캐시에 채움

- 질의 서비스는 번개처럼 (⚡⚡⚡🏃💨💨 )빠르게 동작해야 하므로 아래와 같은 최적화 방안을 생각할 수 있다.
    - **1) AJAX 요청**
        - 보통 웹 애플리케이션의 경우 브라우저는 AJAX 요청을 보내 자동완성된 검색어 목록을 가져온다.
        - AJAX → **서버와 브라우저가 비동기 방식으로 데이터를 교환 ,** 웹페이지에서 기타 코드들을 요청할 경우, 웹페이지를 리로드 하면서 불필요한 리소스가 낭비가 되는데,비동기 방식을 이용하면 필요한 데이터만 불러오면서 리소스 낭비를 줄일 수 있다.
        - 요청을 보내고 받기 위해 페이지를 새로고침 할 필요가 없다.
    - **2) 브라우저 캐싱**
        - 대부분 자동완성 거머색어 제안 결과는 짧은 시간 안에 자주 바뀌지 않는다.
        - **제안된 검색어들을 브라우저 캐시에 넣어두면** 후속 질의의 결과는 해당 캐시에서 바로 가져갈 수 있다.
            - 구글 검색 엔진이 이런 캐시 매커니즘을 사용
                - HTTP 응답에 포함된 **Cache-Control 헤더**에 따라 받은 리소스의 생명 주기가 결정된다.
                    - 참고
                        - 한번 브라우저에 캐시가 저장되면 만료될 때까지 캐시는 계속 브라우저에 남아 있게 됩니다. 때문에 CDN Invalidation을 포함한 서버의 어떤 작업이 있어도 브라우저의 유효한 캐시를 지우기는 어렵다.
                        - 캐시를 없애기 위해서 “CDN Invalidation”을 수행, 하지만 CDN에 저장되어 있는 캐시를 삭제한다는 뜻
                        - 브라우저의 캐시는 다른 곳에 위치하기 때문에 CDN 캐시를 삭제한다고 해서 브라우저 캐시가 삭제되지는 않는다
                        - 경우에 따라 중간 서버나 CDN이 여러 개 있는 경우도 발생하는데, 이 경우 전체 캐시를 날리려면 중간 서버 각각에 대해서 캐시를 삭제해야 한다.
                        - 이렇게 한번 저장된 캐시는 지우기 어렵기 때문에 Cache-Control의 max-age 값은 신중히 설정하여야 합니다.
                - 구글 검색 엔진의 HTTP 응답에 포함된 내용 ⇒ cache-control: private, max-age = 3600
                    - 사용자의 캐시에만 보관하며 1시간 동안 캐시해 둔다.
    - **3) 데이터 샘플링**
        - 모든 질의 결과를 로깅하도록 하면 CPU 자원과 저장공간을 많이 소진하게 된다.
        - 이럴 때 데이터 샘플링 기법이 유용한데, 이는 N개 요청 가운데 1개만 로깅하도록 하는 것.

## 트라이 연산

- 트라이 관련 연산들이 어떻게 동작하는지

### **트라이 생성**

- 작업 서버가 담당하며, 로그나 데이터베이스로부터 취합된 데이터를 이용하여 트라이를 생성한다.

### **트라이 갱신**

- 갱신하는 2가지 방법
    - **1) 매주 한 번 갱신하**는 방법
        - → 새로운 트라이를 만든 다음 기존 트라이를 대체한다.
    - 2) 트라이의 **각 노드를 개별적으로 갱신**하는 방법
        - → 성능이 좋지 않다.
            - 노드를 갱신할 때 상위노드에도 인기 검색어 질의 결과가 보관되기 때문에 그 모든 상위 노드도 갱신해야한다.
            - → 트라이가 작을때는 고려해봄직한 방안.
        - 예시 )
            - beer 검색어의 이용 빈도를 10 → 30으로 갱신
                - 먼저 beer노드를 30으로 변경하고 상위로 이동하면서 갱신한다.
                
                ![사진2.jpeg](https://prod-files-secure.s3.us-west-2.amazonaws.com/e2c6ccd4-4439-43db-96e9-e654aaf4aa71/5926c349-46db-4ccc-b736-02653eaa7487/%E1%84%89%E1%85%A1%E1%84%8C%E1%85%B5%E1%86%AB2.jpeg)
                

### **검색어 삭제**

- 혐오성, 폭력적 등.. 여러 가지로 위험한 질의어를 **자동완성 결과에서 제거**해야 한다.
- → 트라이 캐시 앞에 **필터 계층**을 두고 부적절한 질의어가 반환되지 않도록 할 수 있음.

https://github.com/sangminlee98/system-design-interview/assets/83197138/fd7749a6-4471-4d8e-a876-da38e0853b4b

## 저장소 규모 확장

- 지금까지는 설계였고 이제는 트라이의 크기가 한 서버에 넣기엔 너무 큰 경우 대응할 수 있도록 규모 확장성 문제를 해결해보자
- 영어만 지원하면 되기 때문에, 간단하게는 **첫 글자 기준으로 샤딩**하는 방법을 생각해 볼 수 있음.
    - **두 대의 서버가 필요한 경우**‘a’부터 ‘m’까지로 시작하는 검색어는 첫 번째 서버에, 나머지는 두 번째 서버에 저장한다.
    - **세 대의 서버가 필요한 경우**‘a’부터 ‘i’까지는 첫 번째 서버에, ‘j’부터 ‘r’까지는 두 번째 서버에, 나머지는 세 번째 서버에 저장한다.
    - 이 방법을 쓰는 경우에는 사용 가능한 서버는 최대 26개로 제한된다. → 알파벳이 26자 밖에 없기 때문이다.
        - 이 이상으로 서버 대수를 늘리려면 샤딩을 계층적으로 해야 한다.
        - ex)
            - 검색어의 첫 번째 글자는 첫 번째 레벨의 샤딩에 사용 + 두 번째 글자는 두 번째 레벨의 샤딩에 쓰기
            - ‘a’로 시작하는 검색어를 4개의 서버에 나눠 보관하는 경우
                - 1번째 서버 ⇒ ‘aa’ ~ ‘ag’ 를 보관
                - 2번째 서버 ⇒ ‘ah’ ~ ‘an’ 를 보관
                - 3번째 서버 ⇒ ‘ao’ ~ ‘au’ 를 보관
                - 4번째 서버 ⇒ ‘av’ ~ ‘az’ 를 보관
- 하지만! ‘x’로 시작하는 단어는 상대적으로 적기 때문에 균등하게 각 서버에 배분하기 어렵다.
    - → 이를 해결하기 위해 **과거 질의 패턴을 분석**하여 샤딩할 수 있다.
    - **검색어 대응 샤드 관리자**는 어떤 검색어가 어느 저장소 서버에 저장되는지에 대한 정보를 관리
        - ‘s’로 시작하는 검색어의 양이 ‘u’, ‘v’, ‘w’, ‘x’, ‘y’, ‘z’로 시작하는 검색어를 전부 합친 것과 비슷하다면
        - `’s’`에 대한 샤드 하나와 `‘u’~’z’`까지의 검색어를 위한 샤드 하나를 두어도 충분할 것.

https://github.com/sangminlee98/system-design-interview/assets/83197138/9a00459f-9f46-4066-ad11-7fe42ec920df

# 4단계 : 마무리

- 다국어 지원하기 위해 → 유니코드로 저장
- 국가별 다른 인기 검색어 지원하기 위해 → 트라이를 CDN에 저장하여 응답속도를 높일 수 있다.
- 실시간 검색어 추이 지원하기 위해서 아래와 같은 방법을 사용할 수 있다. (앞서 매주 한 번 갱신하는 방법을 사용한다면 갑자기 뉴스가 나서 실시간으로 변하는 추이를 반영할 수 없을 것이다. 그리고 갱신이 된다고 하더라도 트라이를 구성하는 데 시간이 많이 걸린다. 따라서 아래의 방법을 사용해야한다)
    - 샤딩을 통하여 작업 대상 데이터 양을 줄인다.
        - 샤딩(Sharding)은 데이터를 여러 개의 작은 파티션으로 나누어 저장하고 처리하는 방법입니다. 이를 통해 각 파티션에서의 데이터 처리 및 검색을 병렬로 수행할 수 있어 전체적인 처리 속도를 높일 수 있습니다.
    - 순위 모델을 바꾸어 최근 검색어에 보다 높은 가중치를 준다.
        - 순위 모델을 바꾸어 최근 검색어에 더 높은 가중치를 부여하면 실시간 변화에 민감하게 반응할 수 있습니다. 이를 통해 최신 검색어가 더 빨리 순위에 반영되도록 할 수 있습니다.
    - 스트림 형태의 데이터를 지원하기 위해 아파치 카프카, 아파치 하둡 맵리듀스 등의 시스템을 사용한다.

[data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAASbSURBVHgB7Z0tTytBFIYP914BDiQ4cIADB0EhwYFE8ifq7g/hJ2CRSCQ4kOCobF3ruHk3maS5aSnbdnfPOe/7JE0oCTvTnmc+dvbMsNbr9b5M0PLLBDUSgBwJQI4EIEcCkCMByJEA5EgAciQAORKAHAlAjgQgRwKQIwHIkQDkSAByJAA5EoAcCUCOBCBHApAjAciRAORIAHIkADkSgBwJQI4EIEcCkCMByJEA5EgAciQAOX+MhPX1dTs+Prbt7W3b3d21jY2N6ndgPB7bYDCw4XBor6+v9vHxUb1nIL0Ae3t7dn5+XgV9FhABYuC1v79f/Q4SPD8/28vLi2UmrQA/Cfx34O/wwjXu7u7S9gi/z87O/loyELTr62vb2tqyZcFQcXp6Wv2MXiEb6SaBCDwEWDVFqmykEgABOjo6sqbAtbNJkEaAi4uLRoNfQBmXl5eWhRQCIChlnG6Dk5OTVstrkvACYKLXxJg/D5RZ1hEiE14ABGIVs/26IPgZeoHQAiDwbYz7s4AA0XuB0AIsusizKsrycmRCC+Dhyz84OLDIhBUAra/rHgCgDpGHgbAC7OzsmBc81aUuYQXY3Nw0L3iqS13CCtDFrd8sPNWlLsoIIkcCkBNWAE8JGpGTRcIKgPw9L3iqS13CCvD5+Wle8FSXuoQVAJm8HlK0UAfUJSqhJ4Fvb2/WNcgcjkxoAfDld936oieKhhYAwX96erKuwJ6B6Oni4dcBIEAXvQAC//j4aNEJLwCC30UgUGaGzSIpVgLRC7Q5FKCsLFvG0iwFPzw8tBIUlIGyspDqWcD9/X2jEuDaKCMT6R4GIUBNzAlwzWzBByl3ByNYaK23t7dLP6vHfT6u9/7+bhlZ6/V6X5YYpI0jebRu/mD2wBfSHxCBngAv9ASQ4PDwsErhwvvJE0JGo1EV9H6/72KFsS1SCDAZyFngnh2vVUwSUV4WQUILULZnlR06aMGYqDW1QDN56khZho6+Ghh2DoBgXF1dTZ3koZWvcqWubECdtg0NZUQ+QiakAGjxOA9gHhABj4wXeWyMHgX5/j85Zwi9AXoeD4+n6xJOAASk7nbwkjyCGT0meXg/mcWDYOMsIJwShtaO3mWRHT/odaINCaHmAIsEHyCQOP6tHAHXFKVukSQIsxK4aPDbBnWMdG5ACAHwhUYIfgHzEwwjEXAvQFdHwCzLzc1NiC1jrgXA2I31/Ijbr1HnCEfKuRagq/N/VgXuJLzPB9wKgMBnOITJu8RuBUDXnwHvQ4FLAbDkGrnr/x8MBV7vClwKEHHWPw+vn8mdANlaf8FrL+BOgIytv+Dxs7kSAC0kY+sveOwFXAnQ5bGvbdH0A6m6uBLAw8GPTePtaFk3AmTv/gtYF/A0DLgRgKH1Fzx9VjcCIBuHBU89nRsBkKrFgqfNJm5SwpBGVc7fz/CvWKZRUsk9bS1PvzVMfI+OiiVHApAjAciRAORIAHIkADkSgBwJQI4EIEcCkCMByJEA5EgAciQAORKAHAlAjgQgRwKQIwHIkQDkSAByJAA5EoAcCUCOBCBHApAjAciRAORIAHIkADkSgBwJQI4EIOcfGjV2tEfztqEAAAAASUVORK5CYII=](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAASbSURBVHgB7Z0tTytBFIYP914BDiQ4cIADB0EhwYFE8ifq7g/hJ2CRSCQ4kOCobF3ruHk3maS5aSnbdnfPOe/7JE0oCTvTnmc+dvbMsNbr9b5M0PLLBDUSgBwJQI4EIEcCkCMByJEA5EgAciQAORKAHAlAjgQgRwKQIwHIkQDkSAByJAA5EoAcCUCOBCBHApAjAciRAORIAHIkADkSgBwJQI4EIEcCkCMByJEA5EgAciQAOX+MhPX1dTs+Prbt7W3b3d21jY2N6ndgPB7bYDCw4XBor6+v9vHxUb1nIL0Ae3t7dn5+XgV9FhABYuC1v79f/Q4SPD8/28vLi2UmrQA/Cfx34O/wwjXu7u7S9gi/z87O/loyELTr62vb2tqyZcFQcXp6Wv2MXiEb6SaBCDwEWDVFqmykEgABOjo6sqbAtbNJkEaAi4uLRoNfQBmXl5eWhRQCIChlnG6Dk5OTVstrkvACYKLXxJg/D5RZ1hEiE14ABGIVs/26IPgZeoHQAiDwbYz7s4AA0XuB0AIsusizKsrycmRCC+Dhyz84OLDIhBUAra/rHgCgDpGHgbAC7OzsmBc81aUuYQXY3Nw0L3iqS13CCtDFrd8sPNWlLsoIIkcCkBNWAE8JGpGTRcIKgPw9L3iqS13CCvD5+Wle8FSXuoQVAJm8HlK0UAfUJSqhJ4Fvb2/WNcgcjkxoAfDld936oieKhhYAwX96erKuwJ6B6Oni4dcBIEAXvQAC//j4aNEJLwCC30UgUGaGzSIpVgLRC7Q5FKCsLFvG0iwFPzw8tBIUlIGyspDqWcD9/X2jEuDaKCMT6R4GIUBNzAlwzWzBByl3ByNYaK23t7dLP6vHfT6u9/7+bhlZ6/V6X5YYpI0jebRu/mD2wBfSHxCBngAv9ASQ4PDwsErhwvvJE0JGo1EV9H6/72KFsS1SCDAZyFngnh2vVUwSUV4WQUILULZnlR06aMGYqDW1QDN56khZho6+Ghh2DoBgXF1dTZ3koZWvcqWubECdtg0NZUQ+QiakAGjxOA9gHhABj4wXeWyMHgX5/j85Zwi9AXoeD4+n6xJOAASk7nbwkjyCGT0meXg/mcWDYOMsIJwShtaO3mWRHT/odaINCaHmAIsEHyCQOP6tHAHXFKVukSQIsxK4aPDbBnWMdG5ACAHwhUYIfgHzEwwjEXAvQFdHwCzLzc1NiC1jrgXA2I31/Ijbr1HnCEfKuRagq/N/VgXuJLzPB9wKgMBnOITJu8RuBUDXnwHvQ4FLAbDkGrnr/x8MBV7vClwKEHHWPw+vn8mdANlaf8FrL+BOgIytv+Dxs7kSAC0kY+sveOwFXAnQ5bGvbdH0A6m6uBLAw8GPTePtaFk3AmTv/gtYF/A0DLgRgKH1Fzx9VjcCIBuHBU89nRsBkKrFgqfNJm5SwpBGVc7fz/CvWKZRUsk9bS1PvzVMfI+OiiVHApAjAciRAORIAHIkADkSgBwJQI4EIEcCkCMByJEA5EgAciQAORKAHAlAjgQgRwKQIwHIkQDkSAByJAA5EoAcCUCOBCBHApAjAciRAORIAHIkADkSgBwJQI4EIOcfGjV2tEfztqEAAAAASUVORK5CYII=)
