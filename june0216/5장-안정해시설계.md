> “수평적 규모 확장성을 달성하기 위해 요청 또는 데이터를 서버에 **균등하게** 나누는 것이 중요”
→ 안정 해시의 목표
> 

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/e2c6ccd4-4439-43db-96e9-e654aaf4aa71/4da9013f-0dfe-4604-b3b1-92bab297bf8c/Untitled.png)

# 해시 키 재배치 문제

- N개의 캐시 서버
- 부하를 균등하게 나누는 방법
    - *serverIndex = hash(key) % N (N은 서버 개수)*

| 키 | 해시 | 해시 % 4 (서버 인덱스) |
| --- | --- | --- |
| key0 | 18358617 | 1 |
| key1 | 26143584 | 0 |
| key2 | 18131146 | 2 |
| key3 | 35863496 | 0 |
| key4 | 34085809 | 1 |
| key5 | 27581703 | 3 |
| key6 | 38164978 | 2 |
| key7 | 22530351 | 3 |
- 위의 표를 보면 특정 key가 보관되어 있는 서버를 알아내기 위해 해시에 모듈러 연산 n을 진행하면 어느 서버의 인덱스인지 확인할 수 있다.
- **서버 풀의 크기가 고정되어 있을 때는 데이터 분포가 균등하게 잘 동작한다.**
- **하지만 서버가 추가되거나 기존 서버가 삭제되면 문제가 생긴다**.
    - 예를 들면, 서버 하나가 장애를 일으켜 동작이 중단된다면 서버 풀의 크기(서버 개수 N)가 3으로 변하게 된다. 키에 대한 해시값은 변하진 않지만 모듈러 연산을 적용한 서버 인덱스 값은 완전히 달라지게 된다.

| 키 | 해시 | 해시 % 3 (서버 인덱스) |
| --- | --- | --- |
| key0 | 18358617 | 0 |
| key1 | 26143584 | 0 |
| key2 | 18131146 | 1 |
| key3 | 35863496 | 2 |
| key4 | 34085809 | 1 |
| key5 | 27581703 | 0 |
| key6 | 38164978 | 1 |
| key7 | 22530351 | 0 |

키가 재분배 되었다. 

즉, 서버 하나가 죽어도 대부분 캐시 클라이언트가 데이터가 없는 엉뚱한 서버에 접속하게 된다. 결국 대규모 **캐시 미스(cache miss)**가 발생하게 될 것이다.

# 안정 해시

- 해시 테이블 크기가 조정될 때 평균적으로 오직 k/n개의 키만 재배치하는 해시 기술
- k는 키의 개수이고, n은 슬롯(slot)의 개수

## 해시 공간과 해시 링

- 동작 원리
- 해시 함수 f로는 SHA-1(일방향 암호화 함수)을 사용한다고 가정하자. SHA-1의 해시 공간 범위는 0부터 2^160-1까지라고 알려져있다.
    - x0은 0, xn은 2^160-1이고 나머지 x1부터 xn-1까지는 그 사이의 값을 갖게 될 것이다.
    - 해시 공간
        
        ![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/e2c6ccd4-4439-43db-96e9-e654aaf4aa71/146362b7-d986-43d2-a466-28c6c5172d08/Untitled.png)
        
        - 구부리면 → 해시 링!
            
            ![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/e2c6ccd4-4439-43db-96e9-e654aaf4aa71/0f52eba8-c1f2-4446-b71a-99ad6830fb4b/Untitled.png)
            
        
        ![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/e2c6ccd4-4439-43db-96e9-e654aaf4aa71/6d3ba904-0122-4753-b476-ce68bcddff74/Untitled.png)
        

## 해시 서버

- 4개의 서버를 해시 링에 배치

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/e2c6ccd4-4439-43db-96e9-e654aaf4aa71/406a07e5-4601-4e85-8749-755d99349b84/Untitled.png)

## 해시 키

!https://velog.velcdn.com/images/daehoon12/post/3343dcaf-89f1-4a15-a982-01d22496688e/image.png

- 여기서 사용된 해시 함수는 "해시 키 재배치 문제"에 언급된 함수와 다르며, 나머지 연산은 사용하지 않고 있음에 유의하자.
- 캐시할 키 key0,key1,key2,key3 또한 해시 링 위의 아무 지점에 배치할 수 있다.

## 서버 조회

!https://velog.velcdn.com/images/daehoon12/post/2b42d2cd-7a03-413a-b4ee-60a13c20fbe4/image.png

- 키가 저장되는 서버는, 해당 키의 위치로부터 **시계 방향으로 링을 탐색해서 가장 먼저 만나는 서버**
- key0은 서버0, key1은 서버1, key2은 서버2, key3은 서버3에 저장된다.

## 서버 추가

- 서버를 추가하더라도 키 가운데 일부만 재배치하면 된다.

!https://velog.velcdn.com/images/daehoon12/post/0ab226b9-ee16-42f2-916f-068e2cafb296/image.png

- 서버 4가 추가된 뒤에 key0만 재배치됨을 알 수 있음 → key0위치에서 시계 방향으로 순회했을 때 처음으로 만나게 되는 서버가 서버 4이다.

### 서버 제거

- 하나의 서버가 제거되면 키 가운데 일부만 재배치된다.

!https://velog.velcdn.com/images/daehoon12/post/7bfced6b-e839-4028-a49e-8930ec26874d/image.png

- 서버 1이 삭제되면서 key1이 그 다음 가까운 서버 2로 재배치 되었다.

## 기본 구현법의 두 가지 문제

- 안정 해시 알고리즘은 MIT에서 처음 제안되었고, 절차는 아래와 같다.
    - 서버와 키를 균등 분포(uniform distribution) 해서 함수를 사용해 해시 링에 배치한다.
    - 키의 위치에서 링을 시계 방향으로 탐색하다 만나는 최초의 서버가 키가 저장될 서버다.
- 다만 이 접근법에는 두 가지의 문제가 있다.

**문제 1) 파티션의 크기를 균등하게 유지하는 것이 불가능**

- **서버가 추가되거나 삭제되는 상황**을 감안하면 **파티션의 크기를 균등하게 유지하는 게 불가능**하다.
    - *파티션 = 인접한 서버 사이의 해시 공간

!https://velog.velcdn.com/images/daehoon12/post/85badc50-41f3-45d4-b4a3-f50c3f179467/image.png

- s1이 삭제되는 바람에 s2의 파티션이 다른 파티션 대비 거의 두 배로 커졌다.

**문제 2) 키의 균등 분포(uniform distribution)를 달성하기 어려움**

!https://velog.velcdn.com/images/daehoon12/post/402c4050-bf43-4a30-8ce4-ee75fbf1f767/image.png

- 위와 같이 키와 서버가 분포되어 있을 경우에 s1, s3은 아무 데이터도 갖지 않는다. 대부분의 키는 s2에 보관될 것이다.

위의 두 가지 문제를 해결하기 위해 가상 노드(virual node) 또는 복제(replica)라 불리는 기법이다.

## 가상 노드

- 가상 노드는 실제 노드 또는 서버를 가리키는 노드로서, **하나의 서버는 링 위에 여러 개의 가상 노드를 갖는다.**

!https://velog.velcdn.com/images/daehoon12/post/2ff2cbfa-48ba-47c7-bae9-fc70f012d4bf/image.png

- 위의 그림에서 서버 0과 서버 1은 3개의 가상 노드를 갖는다. (숫자 3은 임의로 정한 것이며, 실제 시스템에는 이보다 훨씬 큰 값을 사용)
- 하나의 서버를 링에 배치하기 위에 세 개의 가상 노드를 사용했다. (서버 0을 링에 배치하기 위해 s0 하나만 쓰는 대신, s0_0, s0_1, s0_2의 세 개 가상 노드를 사용하였다.
    - 즉 각 서버는 하나가 아닌 여러 개 파티션을 관리해야 한다. 그림에서 s0으로 표시된 파티션은 서버 0, s1은 서버 1이 관리하는 파티션이다.

!https://velog.velcdn.com/images/daehoon12/post/edfa0399-7f9c-4834-8bae-51b3fa344dae/image.png

- 키의 위치로부터 시계방향으로 링을 탐색하다 만나는 최초의 가상 노드가 해당 키가 저장될 서버가 된다.
    - k0은 시계방향으로 링을 탐색하다 s1_1을 만나고, 해당 키는 서버 1로 할당이 된다.
- **가상 노드의 개수를 늘리면 키의 분포는 점점 더 균등해진다.** **표준 편차가 작아져서 데이터가 고르게 분**포되기 때문이다.
    - 하지만 가상 노드 데이터를 저장할 공간이 더 많이 필요하다. → 타협적 결정이 필요(시스템 요구사항에 맞도록 가상 노드 개수를 적절히 조정해야한다)

### 재배치할 키 결정

서버가 추가되거나 제거되면 데이터 일부는 재배치해야 한다. 어느 범위의 키가 재배치되어야 할까?

### **서버 추가**

!https://velog.velcdn.com/images/daehoon12/post/292d47a5-0479-4a4b-8905-861a7b87c467/image.png

- 서버 4가 추가되었을 때, 영향을 받는 범위는 s3(반시계 방향에 있는 첫 번째 서버)부터 s4(새로 추가된 노드)다. 즉 **s3부터 s4 사이에 있는 키들을 s4로 재배치**해야 한다.

### **서버 삭제**

!https://velog.velcdn.com/images/daehoon12/post/93fa6ba4-7450-47c6-9e35-27f6e765a890/image.png

- 서버 1가 삭제되었을 때, 영향을 받는 범위는 s0(반시계 방향에 있는 첫 번째 서버)부터 s1(삭제된 노드)다. 즉 **s0부터 s1 사이에 있는 키들을 s2로 재배치**해야 한다.

## 정리

- 안정 해시의 이점
    - 서버가 추가되거나 삭제될 때 재배치되는 키의 수가 최소화된다.
    - 데이터가 보다 균등하게 분포되므로 수평적 규모 확장성을 달성하기 쉽다.
    - 핫스팟 키 문제를 줄인다. 특정한 샤드에 대한 접근이 지나치게 빈번하면 서버 과부하 문제가 생길 수 있다.
        - 케이티 페리, 저스틴 비버, minji Kang 같은 유명인의 데이터가 전부 같은 샤드에 있는 경우를 생각하면 이해하기 쉽다.
- 실제 사용되는 사례
    - 아마존 DynamoDB의 파티셔닝 관련 컴포넌트
    - 아파치 카산드라 클러스터에서 데이터 파티셔닝
    - 디스코드 채팅 어플리케이션
    - Akamai CDN
    - 매그레프 네트워트 부하 분산기
